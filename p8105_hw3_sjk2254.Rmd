---
title: "p8105_hw3_sjk2254"
author: "Sharon Kulali"
output: github_document
---

## SetUp

```{r, message = FALSE}
# loading the needed libraries

library(tidyverse)
library(p8105.datasets)
library(patchwork)
```

```{r}
# setting visuals for plots

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
# loading the dataset

data("instacart")

# looking at the dataset

insta_df = instacart |> 
  as_tibble()
```

Instacart is an online grocery shopping service that allows individuals to shop online from local stores. The platform offers same-day delivery with purchases being able to be delivered within 2 hours. The `insta_df` dataset contains the online grocery orders from Instacart users in 2017. There are `r ncol(insta_df)` variables with `r nrow(insta_df)` observations. More specifically, the dataset has information about identifiers for the order (`order_id`), product (`product_id`), customer (`user_id`), aisle (`aisle_id`), and department (`department_id`). Additionally, there is information about the specific day (`order_dow`) and hour (`order_hour_of_day`) that the orders were placed. In total, there are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

```{r}
# examining the aisles

insta_df |> 
  group_by(aisle_id, aisle) |> 
  count() |> 
  arrange(desc(n))
```

The table above shows the the aisles arranged in decreasing order by most items. Overall, there are 134 different aisles with fresh vegetables and fruits being the most ordered items.

```{r}
# plotting the number of items ordered per aisle

insta_df |> 
  count(aisle) |> 
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust=1)) +
  ggtitle("Number of Items Ordered in Each Aisle") +
  theme(plot.title = element_text(hjust = 0.5))
```

The plot above shows the number of items ordered in each aisle for aisles with more than 10,000 items ordered. You can see that fresh vegetables and fruits are the most ordered items because they have the highest points.

```{r, message = FALSE}
# creating a table for the three most popular items

insta_df |> 
  filter(aisle %in% c("baking ingredients","dog food care","packaged vegetables fruits")) |>  
  group_by(aisle) |> 
  count(product_name) |> 
  arrange(desc(n)) |> 
  top_n(n = 3) |> 
  knitr::kable()
```

The table above shows three most popular items in each of the aisles baking ingredients, dog food care, and packaged vegetables fruits. You can see that packaged vegetables fruits has the most orders out of the three aisles.

```{r, message = FALSE}
# creating a table for ice cream orders

insta_df |> 
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) |> 
  group_by(product_name, order_dow) |> 
  summarize(mean_hr = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hr) |> 
  knitr::kable(digits = 2)
```

The table above shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. You can see that on average, Coffee Ice Cream is ordered more than Pink Lady Apples.

## Problem 2

```{r}
# loading the dataset

data("brfss_smart2010")

# looking at the dataset

brfss_df = brfss_smart2010 |> 
  as_tibble()
```

```{r}
# cleaning the dataset

brfss_df =
  brfss_df |> 
  janitor::clean_names() |> 
  filter(topic == "Overall Health") |> 
  filter(response %in% c("Poor","Fair","Good","Very Good","Excellent")) |> 
  mutate(response = factor(response, levels = c("Poor","Fair","Good","Very Good","Excellent"))) |> 
  mutate(response = ordered(response, levels = c("Poor","Fair","Good","Very Good","Excellent")))
```

The Selected Metropolitan Area Risk Trends (SMART) project uses the Behavioral Risk Factor Surveillance System (BRFSS) to analyze data from counties. The BRFSS is a government data set that is primary used to identify emerging health problems, establish and track health objectives, and develop and evaluate public health policies and programs. The dataset (`brfss_df`) has `r ncol(brfss_df)` variables with `r nrow(brfss_df)` observations and data ranging from years `r brfss_df |> pull(year) |> min()` to `r brfss_df |> pull(year) |> max()`. This dataset focuses on the health topic "Overall Health", specifically for responses from "Poor" to "Excellent".

```{r}
# filtering the data for 2002

brfss_df |> 
  filter(year == "2002") |> 
  group_by(locationabbr) |>
  summarise(num_locations = n_distinct(locationdesc)) |> 
  filter(num_locations >= 7)
```

In 2002, 6 states, CT, FL, MA, NC, NJ, and PA, were observed at 7 or more locations.

```{r, warning = FALSE}
# filtering the data for 2010

brfss_df |> 
  filter(year == "2010") |> 
  group_by(locationabbr) |> 
  summarise(num_locations = n_distinct(locationdesc)) |> 
  filter(num_locations >= 7)
```

In 2010, 14 states, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, and WA, were observed at 7 or more locations.

```{r}
# creating a a limited dataframe

lm_df =
  brfss_df |> 
  filter(response == "Excellent") |> 
  group_by(year, locationabbr) |> 
  summarize(average_data_value = mean(data_value), .groups = "drop")
```

The above dataframe is limited to "Excellent" responses, and contains, year, state, and a variable that averages the data_value across locations within a state.

```{r, warning = FALSE}
# creating a spaghetti plot

lm_df |> 
  ggplot(aes(x = year, y = average_data_value, group = locationabbr, color = locationabbr)) +
  geom_line() +
  labs(
    x = "Year",
    y = "Average Data Value",
    title = "Spaghetti Plot of Average Value Over Time by State"
  ) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(legend.key.size = unit(0.3, "lines"), legend.key.height = unit(0.3, "lines"))
```

The "spaghetti" plot above shows the average percentage of individuals that responded "Excellent" over time within a state. You can see that there is a lot of fluctuation in all the states and there isn't an average greater than 30%.

```{r}
# making a two-panel plot

brfss_df |> 
  filter(year %in% c(2006, 2010), locationabbr == "NY") |> 
  ggplot(aes(x = data_value, fill = response)) +
  geom_histogram(bins = 20, position = "dodge") +
  facet_wrap(~year, nrow = 1) +
  labs(
    x = "Data Value",
    y = "Frequency",
    title = "Distribution of Data Value by Response in NY State"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

The two-panel plot above shows the distribution of data value for responses ("Poor" to "Excellent") among locations in NY state. You can see that on average, 2010 (right side) had higher data values than 2006 (left side).